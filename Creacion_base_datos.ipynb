{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf          \n",
    "\n",
    "## Colocar la direccion de la carpeta de iamgenes originales\n",
    "path_o= '/home/fer/MATLAB_1/DenoisingNetwork/originals/'\n",
    "path_r = '/home/fer/MATLAB_1/DenoisingNetwork/restauradas/'\n",
    "\n",
    "def main():                                                                                                             \n",
    "    print('Hola Luis Fernando')                                                                                         \n",
    "                                                                                                                        \n",
    "def data(path_o):\n",
    "    training_data = []\n",
    "    for img in os.listdir(path_o):\n",
    "        pic_o = cv2.imread(os.path.join(path_o,img),0)\n",
    "        pic_o = cv2.resize(pic_o,(688,688))\n",
    "        training_data.append([pic_o])\n",
    "    training = np.array(training_data).reshape(len(os.listdir(path_o)),pic_o.shape[0],pic_o.shape[1])\n",
    "    return training, training\n",
    "                                                                                                                      \n",
    "def show_figure(x_test):  \n",
    "    ## Generar una figura vacia\n",
    "    fig, axs = plt.subplots(1, 5)                                                                                                                                                                              \n",
    "    plt.gray()                                                                                                          \n",
    "    a=0                                                                                                                 \n",
    "                                                                                                 \n",
    "    for j in range(5):    \n",
    "        ## Graficar en cada posicon del subplot\n",
    "        axs[j].imshow(tf.squeeze(x_test[a]))                                                                                                                                              \n",
    "        a = a+1  \n",
    "            \n",
    "def show_one(x_test,i):\n",
    "    ## Funcion para verificar solo una Imagen\n",
    "    fig, axs = plt.subplots(1, 1)  \n",
    "    fig.tight_layout(pad=-1)                                                                                            \n",
    "    plt.gray()  \n",
    "    axs.imshow(tf.squeeze(x_test[i]))  \n",
    "    \n",
    "\n",
    "def normalization(train, test):\n",
    "    ## Normalizacion de los valores se colocan entre 0-1\n",
    "    train_n = train.astype('float32')/255\n",
    "    test_n = test.astype('float32')/255\n",
    "    train_n = train_n[...,tf.newaxis]\n",
    "    test_n = test_n[...,tf.newaxis]\n",
    "    return train_n, test_n\n",
    "\n",
    "def restauration(data):\n",
    "    data_r = data*255/1\n",
    "    return data_r\n",
    "\n",
    "def noisy(train, test, noisy_factor=0.1):\n",
    "    ## Aumentor ruido artificial a las imagenes\n",
    "    x_train_noisy = train + noisy_factor*tf.random.normal(shape = train.shape)\n",
    "    x_test_noisy = test + noisy_factor*tf.random.normal(shape = test.shape)\n",
    "    \n",
    "    x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.) \n",
    "    x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "    return x_train_noisy, x_test_noisy\n",
    "\n",
    "def plot_noisy(original, noisy,n=5):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.gray()\n",
    "    \n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n , i+1)\n",
    "        plt.title(\"Original\",size=20)\n",
    "        plt.imshow(tf.squeeze(original[i]))\n",
    "        plt.gray()\n",
    "        bx = plt.subplot(2, n, n+ i +1) \n",
    "        plt.title(\"original + noise\", size=20) \n",
    "        plt.imshow(tf.squeeze(noisy[i])) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2DTranspose, Conv2D, Input\n",
    "\n",
    "class NoiseReducer(tf.keras.Model): \n",
    "  def __init__(self):\n",
    "\n",
    "    super(NoiseReducer, self).__init__() \n",
    "\n",
    "    self.encoder = tf.keras.Sequential([ \n",
    "        Input(shape=(688, 688, 1)), \n",
    " \n",
    "    Conv2D(32, (3,3), activation='relu', padding='same', strides=2),\n",
    "    Conv2D(16, (3,3), activation='relu', padding='same', strides=2), \n",
    "    Conv2D(8, (3,3), activation='relu', padding='same', strides=2)]) \n",
    "    \n",
    "    self.decoder = tf.keras.Sequential([ \n",
    "        Conv2DTranspose(8, kernel_size=3, strides=2, activation='relu', padding='same'), \n",
    "        Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "        Conv2DTranspose(32, kernel_size=3, strides=2, activation='relu', padding='same'), \n",
    "\n",
    "        Conv2D(1, kernel_size=(3,3), activation='sigmoid', padding='same')]) \n",
    "  \n",
    "  def call(self, x): \n",
    "    encoded = self.encoder(x) \n",
    "    decoded = self.decoder(encoded) \n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test =data(path_o)\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_figure(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_one(x_test,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_n, x_test_n =normalization(x_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_one(x_train_n,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy, x_test_noisy =noisy(x_train_n, x_test_n,0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_one(x_train_noisy,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_noisy(x_train_n,x_train_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generacion de la clase de la red neuronal\n",
    "autoencoder = NoiseReducer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, \n",
    "                x_train_n, \n",
    "                epochs=600, \n",
    "                shuffle=True, \n",
    "                validation_data=(x_test_noisy, x_test_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs=autoencoder.encoder(x_test_noisy).numpy()\n",
    "decoded_imgs=autoencoder.decoder(encoded_imgs)\n",
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n = 1\n",
    "plt.figure(figsize=(20, 7))\n",
    "plt.gray()\n",
    "for i in range(n): \n",
    "  # display original + noise \n",
    "    bx = plt.subplot(3, n, i + 1) \n",
    "    plt.title(\"original + noise\") \n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i])) \n",
    "    bx.get_xaxis().set_visible(False) \n",
    "    bx.get_yaxis().set_visible(False) \n",
    "\n",
    "    # display reconstruction \n",
    "    cx = plt.subplot(3, n, i + n + 1) \n",
    "    plt.title(\"reconstructed\") \n",
    "    plt.imshow(tf.squeeze(decoded_imgs[i])) \n",
    "    cx.get_xaxis().set_visible(False) \n",
    "    cx.get_yaxis().set_visible(False) \n",
    "\n",
    "    # display original \n",
    "    ax = plt.subplot(3, n, i + 2*n + 1) \n",
    "    plt.title(\"original\") \n",
    "    plt.imshow(tf.squeeze(x_test[i])) \n",
    "    ax.get_xaxis().set_visible(False) \n",
    "    ax.get_yaxis().set_visible(False) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_one(decoded_imgs,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_one(x_test_n,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convertir de tensor a una numpy\n",
    "restauracion = decoded_imgs.numpy()\n",
    "\n",
    "## regresar a escala de 0 255\n",
    "norm_image = cv2.normalize(restauracion, None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "\n",
    "## convertir al tipo de dato inicial\n",
    "norm_image = norm_image.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(os.path.join(path_r , '1.jpg'), norm_image[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "extract_image_patches_v2() missing 5 required positional arguments: 'images', 'sizes', 'strides', 'rates', and 'padding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d5898c1bf24e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_patches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: extract_image_patches_v2() missing 5 required positional arguments: 'images', 'sizes', 'strides', 'rates', and 'padding'"
     ]
    }
   ],
   "source": [
    "from tensorflow import random_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=tf.random_normal_initializer(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1234\n"
     ]
    }
   ],
   "source": [
    "print(a.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
